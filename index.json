[{"authors":null,"categories":null,"content":"I am a PhD student in Machine Learning at CNRS in the Inria ScooL team (formerly SequeL), under the direction of Emilie Kaufmann and Odalric-Ambrym Maillard. I explore alternative approaches to the classical UCB/Thompson Sampling in the Multi-Armed Bandits problem, with algorithms based on sub-sampling or re-sampling of collected data. By using a few information on the arm\u0026rsquo;s distribution, this approach allows to design algorithms that can achieve good theoretical guarantees in diverse settings such as the classical K-armed bandit problems, bandits in non-stationary environments, or risk-aware bandits. My research interests also include reinforcement learning, statistics, and machine learning in general.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://dorian-baudry.netlify.app/author/dorian-baudry/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/dorian-baudry/","section":"authors","summary":"I am a PhD student in Machine Learning at CNRS in the Inria ScooL team (formerly SequeL), under the direction of Emilie Kaufmann and Odalric-Ambrym Maillard. I explore alternative approaches to the classical UCB/Thompson Sampling in the Multi-Armed Bandits problem, with algorithms based on sub-sampling or re-sampling of collected data.","tags":null,"title":"Dorian Baudry","type":"authors"},{"authors":["Dorian Baudry","Romain Gautron","Emilie Kaufmann","Odalric-Ambrym Maillard"],"categories":null,"content":"","date":1612137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612137600,"objectID":"dfa8ce08addb1394f159c35cfb4041b3","permalink":"https://dorian-baudry.netlify.app/publication/ts_cvar/","publishdate":"2021-02-01T00:00:00Z","relpermalink":"/publication/ts_cvar/","section":"publication","summary":"In this paper we study a multi-arm bandit problem in which the quality of each arm is measured by the Conditional Value at Risk (CVaR) at some level alpha of the reward distribution. While existing works in this setting mainly focus on Upper Confidence Bound algorithms, we introduce a new Thompson Sampling approach for CVaR bandits on bounded rewards that is flexible enough to solve a variety of problems grounded on physical resources. Building on a recent work by Riou \u0026 Honda (2020), we introduce B-CVTS for continuous bounded rewards and M-CVTS for multinomial distributions. On the theoretical side, we provide a non-trivial extension of their analysis that enables to theoretically bound their CVaR regret minimization performance. Strikingly, our results show that these strategies are the first to provably achieve asymptotic optimality in CVaR bandits, matching the corresponding asymptotic lower bounds for this setting. Further, we illustrate empirically the benefit of Thompson Sampling approaches both in a realistic environment simulating a use-case in agriculture and on various synthetic examples.","tags":["Source Themes"],"title":"Optimal Thompson Sampling strategies for support-aware CVaR bandits","type":"publication"},{"authors":["Dorian Baudry","Yoan Russac","Olivier Capp√©"],"categories":null,"content":"","date":1607644800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607644800,"objectID":"d7cdabccea55e0b7221a012bc47f52ce","permalink":"https://dorian-baudry.netlify.app/publication/lb_sda/","publishdate":"2020-12-11T00:00:00Z","relpermalink":"/publication/lb_sda/","section":"publication","summary":"There has been a recent surge of interest in nonparametric bandit algorithms based on subsampling. One drawback however of these approaches is the additional complexity required by random subsampling and the storage of the full history of rewards. Our first contribution is to show that a simple deterministic subsampling rule, proposed in the recent work of Baudry et al. (2020) under the name of ''last-block subsampling'', is asymptotically optimal in one-parameter exponential families. In addition, we prove that these guarantees also hold when limiting the algorithm memory to a polylogarithmic function of the time horizon. These findings open up new perspectives, in particular for non-stationary scenarios in which the arm distributions evolve over time. We propose a variant of the algorithm in which only the most recent observations are used for subsampling, achieving optimal regret guarantees under the assumption of a known number of abrupt changes. Extensive numerical simulations highlight the merits of this approach, particularly when the changes are not only affecting the means of the rewards.","tags":["Source Themes"],"title":"On Limited-Memory Subsampling Strategies for Bandits","type":"publication"},{"authors":["Dorian Baudry","Emilie Kaufmann","Odalric-Ambrym Maillard"],"categories":null,"content":"","date":1603365120,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603365120,"objectID":"e3cf8ead8905255109df35f6d668cbb3","permalink":"https://dorian-baudry.netlify.app/publication/sub-sampling/","publishdate":"2020-10-22T12:12:00+01:00","relpermalink":"/publication/sub-sampling/","section":"publication","summary":"In this paper we propose the first multi-armed bandit algorithm based on re-sampling that achieves asymptotically optimal regret simultaneously for different families of arms (namely Bernoulli, Gaussian and Poisson distributions). Unlike Thompson Sampling which requires to specify a different prior to be optimal in each case, our proposal RB-SDA does not need any distribution-dependent tuning. RB-SDA belongs to the family of Sub-sampling Duelling Algorithms (SDA) which combines the sub-sampling idea first used by the BESA [1] and SSMC [2] algorithms with different sub-sampling schemes. In particular, RB-SDA uses Random Block sampling. We perform an experimental study assessing the flexibility and robustness of this promising novel approach for exploration in bandit models.","tags":["Source Themes"],"title":"Sub-Sampling Algorithms for Efficient Non-Parametric Bandit Exploration","type":"publication"}]