[{"authors":null,"categories":null,"content":"I am a PhD student in Machine Learning at CNRS in the Inria ScooL team (formerly SequeL). My supervisors are Emilie Kaufmann and Odalric-Ambryn Maillard. I study the problem of exploration in the bandits models, and explore in particular alternative approaches to the classical UCB/Thompson Sampling algorithms. My research interest also include reinforcement learning and machine learning in general.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://dorian-baudry.netlify.app/author/dorian-baudry/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/dorian-baudry/","section":"authors","summary":"I am a PhD student in Machine Learning at CNRS in the Inria ScooL team (formerly SequeL). My supervisors are Emilie Kaufmann and Odalric-Ambryn Maillard. I study the problem of exploration in the bandits models, and explore in particular alternative approaches to the classical UCB/Thompson Sampling algorithms.","tags":null,"title":"Dorian Baudry","type":"authors"},{"authors":["Dorian Baudry","Emilie Kaufmann","Odalric-Ambrym Maillard"],"categories":null,"content":"","date":1603365120,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603365120,"objectID":"e3cf8ead8905255109df35f6d668cbb3","permalink":"https://dorian-baudry.netlify.app/publication/sub-sampling/","publishdate":"2020-10-22T12:12:00+01:00","relpermalink":"/publication/sub-sampling/","section":"publication","summary":"In this paper we propose the first multi-armed bandit algorithm based on re-sampling that achieves asymptotically optimal regret simultaneously for different families of arms (namely Bernoulli, Gaussian and Poisson distributions). Unlike Thompson Sampling which requires to specify a different prior to be optimal in each case, our proposal RB-SDA does not need any distribution-dependent tuning. RB-SDA belongs to the family of Sub-sampling Duelling Algorithms (SDA) which combines the sub-sampling idea first used by the BESA [1] and SSMC [2] algorithms with different sub-sampling schemes. In particular, RB-SDA uses Random Block sampling. We perform an experimental study assessing the flexibility and robustness of this promising novel approach for exploration in bandit models.","tags":["Source Themes"],"title":"Sub-Sampling Dueling Algorithms for Efficient Bandit Exploration","type":"publication"}]