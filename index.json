[{"authors":null,"categories":null,"content":"I am a PhD student in Machine Learning at CNRS in the Inria ScooL team (formerly SequeL). My supervisors are Emilie Kaufmann and Odalric-Ambryn Maillard. I study the problem of exploration in the bandits models, and explore in particular alternative approaches to the classical UCB/Thompson Sampling algorithms. My research interests also include reinforcement learning and machine learning in general.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://dorian-baudry.netlify.app/author/dorian-baudry/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/dorian-baudry/","section":"authors","summary":"I am a PhD student in Machine Learning at CNRS in the Inria ScooL team (formerly SequeL). My supervisors are Emilie Kaufmann and Odalric-Ambryn Maillard. I study the problem of exploration in the bandits models, and explore in particular alternative approaches to the classical UCB/Thompson Sampling algorithms.","tags":null,"title":"Dorian Baudry","type":"authors"},{"authors":["Dorian Baudry","Romain Gautron","Emilie Kaufmann","Odalric-Ambrym Maillard"],"categories":null,"content":"","date":1607644800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607644800,"objectID":"dfa8ce08addb1394f159c35cfb4041b3","permalink":"https://dorian-baudry.netlify.app/publication/ts_cvar/","publishdate":"2020-12-11T00:00:00Z","relpermalink":"/publication/ts_cvar/","section":"publication","summary":"Risk awareness is an important feature to formulate a variety of real world problems. In this paper we study a multi-arm bandit problem in which the quality of each arm is measured by the Conditional Value at Risk (CVaR) at some level alpha of the reward distribution. While existing works in this setting mainly focus on Upper Confidence Bound algorithms, we introduce the first Thompson Sampling approaches for CVaR bandits. Building on a recent work by Riou and Honda (2020), we propose alpha-NPTS for bounded rewards and alpha-Multinomial-TS for multinomial distributions. We provide a novel lower bound on the CVaR regret which extends the concept of asymptotic optimality to CVaR bandits and prove that alpha-Multinomial-TS is the first algorithm to achieve this lower bound. Finally, we demonstrate empirically the benefit of Thompson Sampling approaches over their UCB counterparts.","tags":["Source Themes"],"title":"Thompson Sampling for CVaR bandits","type":"publication"},{"authors":["Dorian Baudry","Emilie Kaufmann","Odalric-Ambrym Maillard"],"categories":null,"content":"","date":1603365120,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603365120,"objectID":"e3cf8ead8905255109df35f6d668cbb3","permalink":"https://dorian-baudry.netlify.app/publication/sub-sampling/","publishdate":"2020-10-22T12:12:00+01:00","relpermalink":"/publication/sub-sampling/","section":"publication","summary":"In this paper we propose the first multi-armed bandit algorithm based on re-sampling that achieves asymptotically optimal regret simultaneously for different families of arms (namely Bernoulli, Gaussian and Poisson distributions). Unlike Thompson Sampling which requires to specify a different prior to be optimal in each case, our proposal RB-SDA does not need any distribution-dependent tuning. RB-SDA belongs to the family of Sub-sampling Duelling Algorithms (SDA) which combines the sub-sampling idea first used by the BESA [1] and SSMC [2] algorithms with different sub-sampling schemes. In particular, RB-SDA uses Random Block sampling. We perform an experimental study assessing the flexibility and robustness of this promising novel approach for exploration in bandit models.","tags":["Source Themes"],"title":"Sub-Sampling Algorithms for Efficient Non-Parametric Bandit Exploration","type":"publication"}]